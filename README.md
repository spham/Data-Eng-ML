# Data Engineering for Machine Learning

This repository contains the practical exercises and code from the **Pluralsight course "Data Engineering for Machine Learning"** by Brian Letort.

## Course Overview

Expand your software engineering expertise by mastering essential data engineering skills for machine learning. Learn how to gather, clean, validate, and preprocess data effectively, transforming it into ML-ready datasets.

## Repository Structure

This repository is organized into modules that follow the course structure:

### Module 1: Data Ingestion and Profiling
- **Module1_Clip1/**: Data profiling techniques using ydata-profiling
- **Module1_Clip2/**: Data ingestion from CSV files and REST APIs
- **Module1_Clip3/**: Data cleansing and preprocessing techniques
- **Module1_Clip4/**: Data validation and preparation workflows

### Module 2: Advanced Data Processing
- **Module2_Clip2/**: Multi-source data ingestion and merging
- **Module2_Clip3/**: Feature engineering and transformation
- **Module2_Clip4/**: End-to-end data pipeline implementation

## Key Technologies Used

- **Python**: Core programming language
- **Pandas**: Data manipulation and analysis
- **ydata-profiling**: Automated data profiling and quality assessment
- **scikit-learn**: Machine learning preprocessing tools
- **Requests**: API data ingestion
- **Seaborn**: Statistical data visualization

## Getting Started

### Prerequisites

```bash
pip install pandas ydata-profiling scikit-learn requests seaborn
```

### Running the Examples

Each module contains self-contained Python scripts that demonstrate specific data engineering concepts:

1. **Data Profiling**: Generate comprehensive data quality reports
2. **Data Ingestion**: Load data from various sources (CSV, JSON, APIs)
3. **Data Cleansing**: Handle missing values, duplicates, and data quality issues
4. **Feature Engineering**: Create new features and transform existing ones
5. **Pipeline Implementation**: Build end-to-end data processing workflows

## Course Learning Objectives

By working through these examples, you will learn:

- How to profile and assess data quality
- Techniques for ingesting data from multiple sources
- Best practices for data cleansing and validation
- Feature engineering strategies for ML datasets
- Building robust data processing pipelines
- Data transformation and normalization techniques

## Data Sources

The examples use various publicly available datasets:

- **Titanic Dataset**: Passenger survival data for classification tasks
- **Heart Disease Dataset**: Medical data for health prediction models
- **Weather Data**: Real-time weather information from Open-Meteo API
- **Energy Efficiency Data**: Building energy performance metrics

## Output Files

Many scripts generate output files including:
- Cleaned and processed datasets (CSV format)
- Data profiling reports (HTML format)
- Feature engineering reports
- Timestamped pipeline outputs

## Contributing

This repository contains course materials and examples. Feel free to experiment with the code and extend the examples for your own learning.

## License

This repository contains educational materials from a Pluralsight course. Please respect the course content and use responsibly.
